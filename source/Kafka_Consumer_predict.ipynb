{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.112.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>kafka-example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19f601384f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat, lit, from_json\n",
    "from cassandra.cluster import Cluster\n",
    "from time import sleep\n",
    "from IPython.display import display, clear_output\n",
    "import uuid\n",
    "\n",
    "\n",
    "scala_version = '2.12'  # your scala version\n",
    "spark_version = '3.3.0' # your spark version\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',\n",
    "    'org.apache.kafka:kafka-clients:3.5.0' #your kafka version\n",
    "]\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"kafka-example\").config(\"spark.jars.packages\", \",\".join(packages)).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import AutoModel, AutoTokenizer # Thư viện BERT\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Input, Reshape, Concatenate\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user2coder(stng):\n",
    "    lst = stng.split()\n",
    "    # Xóa các tên khách hàng có chữ Mr. hoặc Ms.\n",
    "    if (lst[0] == 'Mr.'): lst.remove('Mr.')\n",
    "    if (lst[0] == 'Ms.'): lst.remove('Ms.')\n",
    "    oupt = lst[0]\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(lst) - 1):\n",
    "        oupt += ' ' + lst[i + 1][0].upper() + '.'\n",
    "\n",
    "    return oupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
    "unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
    "\n",
    "def loaddicchar():\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "        '|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    "\n",
    "dicchar = loaddicchar()\n",
    "\n",
    "# Đưa toàn bộ dữ liệu qua hàm này để chuẩn hóa lại\n",
    "def convert_unicode(txt):\n",
    "    return re.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar[x.group()], txt)\n",
    "\n",
    "def no_accent_vietnamese(s):\n",
    "    convert_unicode(s)\n",
    "    s = re.sub(u'[àáạảãâầấậẩẫăằắặẳẵ]', 'a', s)\n",
    "    s = re.sub(u'[ÀÁẠẢÃĂẰẮẶẲẴÂẦẤẬẨẪ]', 'A', s)\n",
    "    s = re.sub(u'[èéẹẻẽêềếệểễ]', 'e', s)\n",
    "    # s = re.sub('ẹ', 'e', s)\n",
    "    s = re.sub(u'[ÈÉẸẺẼÊỀẾỆỂỄ]', 'E', s)\n",
    "    s = re.sub(u'[òóọỏõôồốộổỗơờớợởỡ]', 'o', s)\n",
    "    s = re.sub(u'[ÒÓỌỎÕÔỒỐỘỔỖƠỜỚỢỞỠ]', 'O', s)\n",
    "    s = re.sub(u'[ìíịỉĩ]', 'i', s)\n",
    "    s = re.sub(u'[ÌÍỊỈĨ]', 'I', s)\n",
    "    s = re.sub(u'[ùúụủũưừứựửữ]', 'u', s)\n",
    "    s = re.sub(u'[ƯỪỨỰỬỮÙÚỤỦŨ]', 'U', s)\n",
    "    s = re.sub(u'[ỳýỵỷỹ]', 'y', s)\n",
    "    s = re.sub(u'[ỲÝỴỶỸ]', 'Y', s)\n",
    "    s = re.sub(u'Đ', 'D', s)\n",
    "    s = re.sub(u'đ', 'd', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "bang_nguyen_am = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
    "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
    "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
    "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
    "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
    "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
    "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
    "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
    "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
    "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
    "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
    "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
    "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
    "\n",
    "nguyen_am_to_ids = {}\n",
    "\n",
    "for i in range(len(bang_nguyen_am)):\n",
    "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
    "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
    "\n",
    "def is_valid_vietnam_word(word):\n",
    "    chars = list(word)\n",
    "    nguyen_am_index = -1\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x != -1:\n",
    "            if nguyen_am_index == -1:\n",
    "                nguyen_am_index = index\n",
    "            else:\n",
    "                if index - nguyen_am_index != 1:\n",
    "                    return False\n",
    "                nguyen_am_index = index\n",
    "    return True\n",
    "\n",
    "def chuan_hoa_dau_tu_tieng_viet(word):\n",
    "    if not is_valid_vietnam_word(word):\n",
    "        return word\n",
    "\n",
    "    chars = list(word)\n",
    "    dau_cau = 0\n",
    "    nguyen_am_index = []\n",
    "    qu_or_gi = False\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x == -1:\n",
    "            continue\n",
    "        elif x == 9:  # check qu\n",
    "            if index != 0 and chars[index - 1] == 'q':\n",
    "                chars[index] = 'u'\n",
    "                qu_or_gi = True\n",
    "        elif x == 5:  # check gi\n",
    "            if index != 0 and chars[index - 1] == 'g':\n",
    "                chars[index] = 'i'\n",
    "                qu_or_gi = True\n",
    "        if y != 0:\n",
    "            dau_cau = y\n",
    "            chars[index] = bang_nguyen_am[x][0]\n",
    "        if not qu_or_gi or index != 1:\n",
    "            nguyen_am_index.append(index)\n",
    "    if len(nguyen_am_index) < 2:\n",
    "        if qu_or_gi:\n",
    "            if len(chars) == 2:\n",
    "                x, y = nguyen_am_to_ids.get(chars[1])\n",
    "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
    "            else:\n",
    "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
    "                if x != -1:\n",
    "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
    "                else:\n",
    "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
    "            return ''.join(chars)\n",
    "        return word\n",
    "\n",
    "    for index in nguyen_am_index:\n",
    "        x, y = nguyen_am_to_ids[chars[index]]\n",
    "        if x == 4 or x == 8:  # ê, ơ\n",
    "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
    "            return ''.join(chars)\n",
    "\n",
    "    if len(nguyen_am_index) == 2:\n",
    "        if nguyen_am_index[-1] == len(chars) - 1:\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
    "        else:\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "    else:\n",
    "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "    return ''.join(chars)\n",
    "\n",
    "#Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n",
    "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    for index, word in enumerate(words):\n",
    "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
    "        if len(cw) == 3:\n",
    "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
    "        words[index] = ''.join(cw)\n",
    "    return ' '.join(words)\n",
    "\n",
    "#Chuẩn hóa viết tắt\n",
    "def chuan_hoa_viet_tat_tieng_viet(sentence):\n",
    "  sentence = re.sub(r'\\b[k][s]\\b', 'khách sạn', sentence)\n",
    "  sentence = re.sub(r'\\b[n][v]\\b', 'nhân viên', sentence)\n",
    "  sentence = re.sub(r'\\b[d][v]\\b', 'dịch vụ', sentence)\n",
    "  sentence = re.sub(r'\\b[v][i][e][w]\\b', 'khung cảnh', sentence)\n",
    "  sentence = sentence.replace('check out', 'trả phòng')\n",
    "  sentence = sentence.replace('checkout', 'trả phòng')\n",
    "  sentence = sentence.replace('check in', 'nhận phòng')\n",
    "  sentence = sentence.replace('checkin', 'nhận phòng')\n",
    "  sentence = sentence.replace('delay', 'trì hoãn')\n",
    "  sentence = sentence.replace('resort', 'khu nghĩ dưỡng')\n",
    "\n",
    "  sentence = re.sub(r'\\b[o][k]\\b', 'tốt', sentence)\n",
    "  sentence = re.sub(r'\\b[v][s]\\b', 'với', sentence)\n",
    "  sentence = re.sub(r'\\b[k][o]?\\b', 'không', sentence)\n",
    "  sentence = re.sub(r'\\b[n][i][c][e]?\\b', 'tuyệt vời', sentence)\n",
    "  return sentence\n",
    "\n",
    "from underthesea import word_tokenize\n",
    "def text_preprocess(document):\n",
    "    # chuẩn hóa unicode\n",
    "    document = convert_unicode(document)\n",
    "    # chuẩn hóa cách gõ dấu tiếng Việt\n",
    "    document = chuan_hoa_dau_cau_tieng_viet(document)\n",
    "    # đưa về lower (chữ thường)\n",
    "    document = document.lower()\n",
    "    # xóa các ký tự không cần thiết\n",
    "    document = re.sub(r'[^\\s\\w%_]',' ',document)\n",
    "    # xóa khoảng trắng thừa\n",
    "    document = re.sub(r'\\s+', ' ', document).strip()\n",
    "    # Sửa chính tả, lỗi cú pháp, viết tắt, tiếng anh lẫn vào, không dấu bằng tay trên gg sheet\n",
    "    document = chuan_hoa_viet_tat_tieng_viet(document)\n",
    "    # tách từ\n",
    "    document = word_tokenize(document, format=\"text\")\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Các hàm cần dùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load danh sách stopword\n",
    "def load_stopwords():\n",
    "    stopwords = []\n",
    "    with open(\"vietnamese-stopwords.txt\", encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        stopwords.append(line.replace(\"\\n\",\"\"))\n",
    "    return stopwords\n",
    "\n",
    "# Loại bỏ stopword\n",
    "def remove_stopwords(line, stopwords):\n",
    "    words = []\n",
    "    for word in line.strip().split():\n",
    "        if word not in stopwords:\n",
    "            words.append(word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Tokenize comment\n",
    "def vietnamese_tokenized(X):\n",
    "  v_tokenized=[]\n",
    "  for line in X:\n",
    "    # remove_stopwords(line, stopwords)\n",
    "    line = tokenizer.encode(line)\n",
    "    v_tokenized.append(line)\n",
    "  return v_tokenized\n",
    "\n",
    "# Chèn thêm số 1 vào cuối câu nếu như không đủ 80 từ\n",
    "def padding(max_len, X):\n",
    "    padded = []\n",
    "    tokenized = vietnamese_tokenized(X)\n",
    "    for i in tokenized:\n",
    "      if (max_len - len(i)) >= 0:\n",
    "        cmt_token = i + [1] * (max_len - len(i))\n",
    "        padded.append(cmt_token)\n",
    "      else:\n",
    "        cmt_token = i[:80]\n",
    "        padded.append(cmt_token)\n",
    "    padded = np.array(padded)\n",
    "    return padded\n",
    "\n",
    "def X_tensor(X):\n",
    "  max_len = 80\n",
    "  X = np.array(padding(max_len, X))\n",
    "  X_tensor = torch.tensor(X).to(torch.long)\n",
    "  return X_tensor\n",
    "\n",
    "def mask(X):\n",
    "  max_len=80\n",
    "  X = np.array(padding(max_len, X))\n",
    "  attention_mask = np.where(X == 1, 0, 1)\n",
    "  return attention_mask\n",
    "\n",
    "def mask_tensor(X):\n",
    "  max_len=80\n",
    "  attention_mask_tensor = torch.tensor(mask(X))\n",
    "  return attention_mask_tensor\n",
    "\n",
    "# Lấy features đầu ra từ BERT\n",
    "def get_features(X):\n",
    "  with torch.no_grad():\n",
    "      last_hidden_states = phobert(input_ids= X_tensor(X), attention_mask = mask_tensor(X))\n",
    "  features = last_hidden_states[0][:, :, :].numpy()\n",
    "  return features\n",
    "\n",
    "def get_user_id(user_name, df_last_info):\n",
    "  for i in range(len(df_last_info)):\n",
    "    if user_name == df_last_info[\"User_name\"][i]:\n",
    "      user_id = df_last_info[\"UserId\"][i]\n",
    "      user_id_frame = df_last_info[[\"UserId\",\"User_name\"]].loc[i:i]\n",
    "      break\n",
    "  return user_id, user_id_frame\n",
    "\n",
    "def get_hotel_id(df_last_info):\n",
    "  hotel_name = get_hotel_name()\n",
    "  for i in range(len(df_last_info)):\n",
    "    if hotel_name == df_last_info[\"Hotel_name\"][i]:\n",
    "      hotel_id  = df_last_info['HotelId'][i]\n",
    "      hotel_id_frame  = df_last_info[['HotelId','Hotel_name']].loc[i:i]\n",
    "      break\n",
    "  return hotel_id, hotel_id_frame\n",
    "\n",
    "# Hàm dự đoán\n",
    "def pred_func_1sample(features):\n",
    "  y_pred = predict_model.predict(features)\n",
    "  pred =[]\n",
    "  count = 0\n",
    "  threshold = 0.5\n",
    "  for i in y_pred[0][0]:\n",
    "    if i >= threshold: pred.append(1)\n",
    "    else: pred.append(0)\n",
    "    count +=1\n",
    "  pred.append(np.argmax(y_pred[1][0]))\n",
    "\n",
    "  pred = pd.DataFrame(pred).T\n",
    "  pred.columns = ['Service', 'Infrastructure','Sanitary','Location','Attitude']\n",
    "\n",
    "  return pred\n",
    "\n",
    "# Lịch sử feedback người dùng\n",
    "def feedback_history(X):\n",
    "  X = df_last_info.loc[:,['UserId', 'HotelId', 'Location_hotel','Comment', 'Rating']] # 'Location_hotel': nếu trong DB thì ko cần lấy\n",
    "  X = pd.concat([X], axis = 0, ignore_index=True)\n",
    "  return X\n",
    "\n",
    "# Lấy kết quả đánh giá\n",
    "def get_ratings(user_id):\n",
    "  df_history = feedback_history(df_last_info)\n",
    "  # Lịch sử khách sạn mà user đã đi\n",
    "  hotels_went_by_user = df_history[df_history.UserId == user_id]\n",
    "  hotels_went_by_user_df = hotels_went_by_user\n",
    "  # Lịch sử khách sạn mà user chưa đi\n",
    "  hotels_not_went_by_user = df_history[~df_history[\"HotelId\"].isin(hotels_went_by_user.HotelId.value_counts().index)]\n",
    "  # Lấy unique hotel ID từ hotel user chưa đi\n",
    "  id_hotels_not_went_by_user = hotels_not_went_by_user['HotelId']\n",
    "  id_hotels_not_went_by_user = pd.DataFrame(id_hotels_not_went_by_user).HotelId.value_counts().index\n",
    "  id_hotels_not_went_by_user = list(id_hotels_not_went_by_user)\n",
    "  # chuyển về list 2x2\n",
    "  id_hotels_not_went_by_user = [[x] for x in id_hotels_not_went_by_user]\n",
    "  # Lấy cmt gần nhất của user\n",
    "  context = feedback.loc[0]\n",
    "\n",
    "  user_hotel_array = np.hstack(( [[user_id]] * len(id_hotels_not_went_by_user), id_hotels_not_went_by_user,\n",
    "                               [context] * len(id_hotels_not_went_by_user) ))\n",
    "\n",
    "  userID_hotel_pred = [user_hotel_array[:,:1].astype(int),\n",
    "                    user_hotel_array[:,1:2].astype(int),\n",
    "                    user_hotel_array[:,2:6].astype(int),\n",
    "                    user_hotel_array[:,-1].astype(int)]\n",
    "\n",
    "  ratings = recommend_model.predict(userID_hotel_pred).flatten()\n",
    "  return hotels_went_by_user_df, ratings\n",
    "\n",
    "# Lấy danh sách id khách sạn được gợi ý\n",
    "def get_recommended_hotel_id(user_id):\n",
    "  df_history = feedback_history(df_last_info)\n",
    "  hotels_went_by_user_df, ratings = get_ratings(user_id)\n",
    "  # Lịch sử khách sạn mà user đã đi\n",
    "  hotels_went_by_user = df_history[df_history.UserId == user_id]\n",
    "  # Lịch sử khách sạn mà user chưa đi\n",
    "  hotels_not_went_by_user = df_history[~df_history[\"HotelId\"].isin(hotels_went_by_user.HotelId.value_counts().index)]\n",
    "  # Lấy unique hotel ID từ hotel user chưa đi\n",
    "  id_hotels_not_went_by_user = hotels_not_went_by_user['HotelId']\n",
    "  id_hotels_not_went_by_user = pd.DataFrame(id_hotels_not_went_by_user).HotelId.value_counts().index\n",
    "  id_hotels_not_went_by_user = list(id_hotels_not_went_by_user)\n",
    "  # chuyển về list 2x2\n",
    "  id_hotels_not_went_by_user = [[x] for x in id_hotels_not_went_by_user]\n",
    "  # Lấy top 10 rating\n",
    "  top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "  recommended_hotels_ids = [id_hotels_not_went_by_user[x][0] for x in top_ratings_indices]\n",
    "  return hotels_went_by_user_df, recommended_hotels_ids\n",
    "\n",
    "def get_hotel_name():\n",
    "  hotel_name = df_hotel.Hotel_name\n",
    "  return hotel_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 368, Number of hotels: 137, Min rating: 4.5, Max rating: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# lấy từ Dataset\n",
    "df_last_info = pd.read_csv('dataset_final.csv')\n",
    "\n",
    "# tokenize User_name, Hotel_name\n",
    "\n",
    "user_ids = df_last_info[\"User_name\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "user_encoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "\n",
    "hotel_ids = df_last_info[\"Hotel_name\"].unique().tolist()\n",
    "hotel2hotel_encoded = {x: i for i, x in enumerate(hotel_ids)}\n",
    "hotel_encoded2hotel = {i: x for i, x in enumerate(hotel_ids)}\n",
    "\n",
    "df_last_info[\"UserId\"] = df_last_info[\"User_name\"].map(user2user_encoded)\n",
    "df_last_info[\"HotelId\"] = df_last_info[\"Hotel_name\"].map(hotel2hotel_encoded)\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_hotels = len(hotel2hotel_encoded)\n",
    "df_last_info[\"Rating\"] = df_last_info[\"Rating\"].values.astype(np.float32)\n",
    "\n",
    "min_rating = min(df_last_info[\"Rating\"])\n",
    "max_rating = max(df_last_info[\"Rating\"])\n",
    "\n",
    "print(\"Number of users: {}, Number of hotels: {}, Min rating: {}, Max rating: {}\".format(num_users, num_hotels, min_rating, max_rating))\n",
    "\n",
    "# Load bert pretrained\n",
    "def load_bert():\n",
    "    v_phobert = AutoModel.from_pretrained(\"vinai/phobert-base\") # vinai/phobert-large\n",
    "    v_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)# vinai/phobert-large\n",
    "    return v_phobert, v_tokenizer\n",
    "\n",
    "def predict_model():\n",
    "  max_len = 80\n",
    "  text_input = tf.keras.layers.Input(shape=(max_len, 768))\n",
    "  net = Bidirectional(LSTM(128, return_sequences = False))(text_input)\n",
    "  net = tf.keras.layers.Dropout(0.5) (net)\n",
    "  net = tf.keras.layers.Dense(384, activation='ReLU', kernel_regularizer = regularizers.l2(0.01)) (net)\n",
    "  net = BatchNormalization() (net)\n",
    "  net = tf.keras.layers.Dense(192, activation='ReLU', kernel_regularizer = regularizers.l2(0.03)) (net)\n",
    "\n",
    "  net_1 = tf.keras.layers.Dense(96, activation='ReLU') (net)\n",
    "  net_1 = tf.keras.layers.Dropout(0.5) (net_1)\n",
    "  net_1 = tf.keras.layers.Dense(48, activation='ReLU') (net_1)\n",
    "  net_1 = tf.keras.layers.Dropout(0.3) (net_1)\n",
    "  net_output1 = tf.keras.layers.Dense(4, activation='sigmoid', name = 'output1') (net_1)\n",
    "\n",
    "  net_2 = tf.keras.layers.Dense(32, activation='ReLU') (net)\n",
    "  net_2 = tf.keras.layers.Dropout(0.4) (net_2)\n",
    "  net_output2 = tf.keras.layers.Dense(3, activation='softmax', name = 'output2') (net_2)\n",
    "\n",
    "  output_list = [net_output1, net_output2]\n",
    "  predict_model = tf.keras.Model(inputs = text_input, outputs = output_list)\n",
    "  return predict_model\n",
    "\n",
    "user_embed = 40\n",
    "hotel_embed = 15\n",
    "topic_embed = 5\n",
    "\n",
    "def create_model(user_embed, hotel_embed, topic_embed):\n",
    "  # Create two input layers\n",
    "  user_id_input = Input(shape=[1], name='user')\n",
    "  hotel_id_input = Input(shape=[1], name='hotel')\n",
    "  # Create separate embeddings for users and hotels\n",
    "  user_embedding = Embedding( input_dim=500,\n",
    "                              output_dim=user_embed,\n",
    "                              input_length=1,\n",
    "                              name='user_embedding')(user_id_input)\n",
    "  hotel_embedding = Embedding(input_dim=300,\n",
    "                              output_dim=hotel_embed,\n",
    "                              input_length=1,\n",
    "                              name='hotel_embedding')(hotel_id_input)\n",
    "  # Context\n",
    "  topic_input = Input(shape=[4], name='topic')\n",
    "  topic_embedding = Embedding(input_dim=10,\n",
    "                              output_dim=topic_embed,\n",
    "                              input_length=4,\n",
    "                              name='topic_embedding')(topic_input)\n",
    "  sentiment_input = Input(shape=[1], name='sentiment')\n",
    "  # Reshape both embedding layers\n",
    "  user_vectors = Reshape([user_embed])(user_embedding)\n",
    "  hotel_vectors = Reshape([hotel_embed])(hotel_embedding)\n",
    "  topic_vectors = Reshape([topic_embed*4])(topic_embedding)\n",
    "  # Concatenate all layers into one vector\n",
    "  concatenate_context = Concatenate(name='concatenate_context')([sentiment_input, topic_vectors])\n",
    "  concatenate_context = Dense(21, activation='relu')(concatenate_context)\n",
    "  concatenate = Concatenate()([user_vectors, hotel_vectors, concatenate_context])\n",
    "  # Dense\n",
    "  dense = Dense(32, activation='relu')(concatenate)\n",
    "  dense = Dropout(0.2)(dense)\n",
    "  output = Dense(1)(dense)\n",
    "\n",
    "  model = Model(inputs=[user_id_input, hotel_id_input, topic_input, sentiment_input], outputs=output)\n",
    "  return model\n",
    "\n",
    "stopwords = load_stopwords()\n",
    "phobert, tokenizer = load_bert()\n",
    "\n",
    "# Load model Sentiment\n",
    "predict_model = predict_model()\n",
    "predict_model.load_weights('checkpoint/checkpoint_PhoBERT_bi-acc1-0.81_acc2-0.82.hdf5')\n",
    "\n",
    "# Load model RRS\n",
    "recommend_model = create_model(user_embed, hotel_embed, topic_embed)\n",
    "recommend_model.load_weights('checkpoint\\checkpoint_Recommend_mse-0.0268.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = 'TestTopic'\n",
    "kafka_server = 'localhost:9092'\n",
    "\n",
    "kafkaDf = spark.read\\\n",
    "    .format(\"kafka\")\\\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_server)\\\n",
    "    .option(\"subscribe\", topic_name)\\\n",
    "    .option(\"startingOffsets\", \"earliest\")\\\n",
    "    .load()\n",
    "\n",
    "schema = spark.read\\\n",
    "    .json(spark.sparkContext\\\n",
    "        .parallelize([{\"User_name\": \"string\", \"Location_hotel\": \"string\", \n",
    "                       \"Hotel_name\": \"string\", \"Rating\": \"string\", \n",
    "                       \"Comment\": \"string\"}])).schema\n",
    "\n",
    "batch_hotel = kafkaDf\\\n",
    "    .select(from_json(kafkaDf.value.cast(\"string\"), schema)\\\n",
    "            .alias(\"data\"))\\\n",
    "    .select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotel = batch_hotel.toPandas().iloc[-1]\n",
    "df_hotel.Comment = text_preprocess(df_hotel.Comment)\n",
    "df_hotel.User_name = user2coder(no_accent_vietnamese(df_hotel.User_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster = Cluster(['127.0.0.1'], port=9042)\n",
    "# session = cluster.connect('rrs_hotel')\n",
    "\n",
    "# num_id = session.execute(\"SELECT COUNT(*) FROM user_reviews;\").one()[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing live view refreshed every 5 seconds\n",
      "Seconds passed: 30\n",
      "Data raw:\n",
      "-------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Comment           Không có xe đưa đón sân bay. Khu nghỉ dưỡng ở ...\n",
       "Hotel_name                           Khu nghỉ dưỡng Fusion Cam Ranh\n",
       "Location_hotel                                            Nha Trang\n",
       "Rating                                                          8.0\n",
       "User_name                                              Nguyen H. T.\n",
       "Name: 144, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "History:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>HotelId</th>\n",
       "      <th>Location_hotel</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khu nghỉ dưỡng Fusion Cam Ranh</td>\n",
       "      <td>Nha Trang</td>\n",
       "      <td>không_có xe đưa_đón sân_bay khu nghỉ_dưỡng ở m...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khu Nghỉ Dưỡng Best Western Premier Sonasea Ph...</td>\n",
       "      <td>Phú Quốc</td>\n",
       "      <td>không_có trái_cây chào_mừng nên hơi buồn xíu đ...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khu nghỉ dưỡng Pandanus Phan Thiết</td>\n",
       "      <td>Phan Thiết</td>\n",
       "      <td>mình đã có kỳ nghỉ ở pandanus khu_nghỉ_mát mũi...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khách Sạn LADALAT</td>\n",
       "      <td>Đà Lạt</td>\n",
       "      <td>khách_sạn có dịch_vụ tốt mình hài_lòng khi ngh...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khu nghỉ dưỡng Movenpick Cam Ranh</td>\n",
       "      <td>Nha Trang</td>\n",
       "      <td>trẻ con nhà mình thích tới nỗi không_muốn về n...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khu nghỉ dưỡng Pandanus Phan Thiết</td>\n",
       "      <td>Phan Thiết</td>\n",
       "      <td>mình đã có kỳ nghỉ ở pandanus khu_nghỉ_mát mũi...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>JW Marriott Phu Quoc Emerald Bay Resort &amp; Spa</td>\n",
       "      <td>Phú Quốc</td>\n",
       "      <td>nhân_viên nhiệt_tình giá_cả hợp_lý chắc_chắn t...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khu nghỉ dưỡng Vinpearl Nha Trang</td>\n",
       "      <td>Nha Trang</td>\n",
       "      <td>nhìn chung tôi hài_lòng về khách_sạn này cảm_ơ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Lasenta Boutique Hotel Hoian</td>\n",
       "      <td>Hội An</td>\n",
       "      <td>rất thích mọi thứ thật tuyệt_vời</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khách sạn Four Points by Sheraton Đà Nẵng</td>\n",
       "      <td>Đà Nẵng</td>\n",
       "      <td>khách_sạn dịch_vụ tốt nằm giữa trung_tâm thành...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khu nghỉ dưỡng Vinpearl Nha Trang</td>\n",
       "      <td>Nha Trang</td>\n",
       "      <td>khách_sạn ở thoải_mái phòng ốc đẹp dịch_vụ và ...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khách sạn Mường Thanh Luxury Sài Gòn</td>\n",
       "      <td>Hồ Chí Minh</td>\n",
       "      <td>tham_quan tốt nhân_viên thân_thiện thoải_mái đ...</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>Nguyen H. T.</td>\n",
       "      <td>Khách sạn D'Lecia Ha Long</td>\n",
       "      <td>Hạ Long</td>\n",
       "      <td>phòng đẹp trang_trí nội_thất kiểu sang_trọng n...</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            UserId                                            HotelId  \\\n",
       "6     Nguyen H. T.                     Khu nghỉ dưỡng Fusion Cam Ranh   \n",
       "87    Nguyen H. T.  Khu Nghỉ Dưỡng Best Western Premier Sonasea Ph...   \n",
       "243   Nguyen H. T.                 Khu nghỉ dưỡng Pandanus Phan Thiết   \n",
       "330   Nguyen H. T.                                  Khách Sạn LADALAT   \n",
       "549   Nguyen H. T.                  Khu nghỉ dưỡng Movenpick Cam Ranh   \n",
       "562   Nguyen H. T.                 Khu nghỉ dưỡng Pandanus Phan Thiết   \n",
       "802   Nguyen H. T.      JW Marriott Phu Quoc Emerald Bay Resort & Spa   \n",
       "1021  Nguyen H. T.                  Khu nghỉ dưỡng Vinpearl Nha Trang   \n",
       "1342  Nguyen H. T.                       Lasenta Boutique Hotel Hoian   \n",
       "1430  Nguyen H. T.          Khách sạn Four Points by Sheraton Đà Nẵng   \n",
       "1499  Nguyen H. T.                  Khu nghỉ dưỡng Vinpearl Nha Trang   \n",
       "1682  Nguyen H. T.               Khách sạn Mường Thanh Luxury Sài Gòn   \n",
       "2213  Nguyen H. T.                          Khách sạn D'Lecia Ha Long   \n",
       "\n",
       "     Location_hotel                                            Comment  Rating  \n",
       "6         Nha Trang  không_có xe đưa_đón sân_bay khu nghỉ_dưỡng ở m...     8.0  \n",
       "87         Phú Quốc  không_có trái_cây chào_mừng nên hơi buồn xíu đ...     8.0  \n",
       "243      Phan Thiết  mình đã có kỳ nghỉ ở pandanus khu_nghỉ_mát mũi...     8.0  \n",
       "330          Đà Lạt  khách_sạn có dịch_vụ tốt mình hài_lòng khi ngh...    10.0  \n",
       "549       Nha Trang  trẻ con nhà mình thích tới nỗi không_muốn về n...    10.0  \n",
       "562      Phan Thiết  mình đã có kỳ nghỉ ở pandanus khu_nghỉ_mát mũi...     8.0  \n",
       "802        Phú Quốc  nhân_viên nhiệt_tình giá_cả hợp_lý chắc_chắn t...    10.0  \n",
       "1021      Nha Trang  nhìn chung tôi hài_lòng về khách_sạn này cảm_ơ...     9.0  \n",
       "1342         Hội An                   rất thích mọi thứ thật tuyệt_vời    10.0  \n",
       "1430        Đà Nẵng  khách_sạn dịch_vụ tốt nằm giữa trung_tâm thành...    10.0  \n",
       "1499      Nha Trang  khách_sạn ở thoải_mái phòng ốc đẹp dịch_vụ và ...    10.0  \n",
       "1682    Hồ Chí Minh  tham_quan tốt nhân_viên thân_thiện thoải_mái đ...     9.4  \n",
       "2213        Hạ Long  phòng đẹp trang_trí nội_thất kiểu sang_trọng n...     9.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 hotel recommendations:\n",
      "--------------------------------\n",
      "Dalat Edensee Lake Resort & Spa\n",
      "InterContinental Đà Nẵng Sun Peninsula Resort\n",
      "New Style House Hotel\n",
      "Khu nghỉ dưỡng Amiana Nha Trang\n",
      "Vinpearl Condotel Beachfront Nha Trang\n",
      "Khu nghỉ dưỡng Crown Retreat Quy Nhơn\n",
      "Khu nghỉ dưỡng Holiday Inn Hồ Tràm\n",
      "Khu nghỉ dưỡng Melia Đà Nẵng Beach\n",
      "Khu nghỉ dưỡng Seava Hồ Tràm\n",
      "Khu nghỉ dưỡng The Anam Nha Trang\n",
      "break\n",
      "Live view ended...\n"
     ]
    }
   ],
   "source": [
    "for x in range(0, 2000):\n",
    "    try:\n",
    "        print(\"Showing live view refreshed every 5 seconds\")\n",
    "        print(f\"Seconds passed: {x*5}\")\n",
    "        df_hotel = batch_hotel.toPandas().iloc[-1]\n",
    "        print(\"Data raw:\")\n",
    "        print(\"-------------------------------------------------------------------\")\n",
    "        display(df_hotel)\n",
    "\n",
    "        df_hotel.Comment = text_preprocess(df_hotel.Comment)\n",
    "        df_hotel.User_name = user2coder(no_accent_vietnamese(df_hotel.User_name))\n",
    "\n",
    "        # print(\"Data pre-processing:\")\n",
    "        # print(\"-------------------------------------------------------------------\")\n",
    "        # display(df_hotel)\n",
    "        # print(\"Predictting...\")\n",
    "\n",
    "        # y_pred = pred_func_1sample(get_features(pd.DataFrame(df_hotel).iloc[0]))\n",
    "        # print(\"Result predict:\")\n",
    "        # print(\"-------------------------------------------------------------------\")\n",
    "        # display(y_pred)\n",
    "\n",
    "        if df_last_info.User_name.str.contains(df_hotel.User_name).any():\n",
    "            if df_last_info.Hotel_name.str.contains(df_hotel.Hotel_name).any():\n",
    "                user_id, user_id_frame = get_user_id(df_hotel.User_name, df_last_info)\n",
    "                user_id_frame = user_id_frame.drop(['User_name'], axis = 1).reset_index().drop(['index'], axis = 1)\n",
    "                hotel_id, hotel_id_frame= get_hotel_id(df_last_info)\n",
    "                hotel_id_frame = hotel_id_frame.drop(['Hotel_name'], axis = 1).reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "                feedback = pd.concat([user_id_frame, pd.concat([hotel_id_frame, y_pred], axis = 1)], axis = 1)\n",
    "\n",
    "                hotels_went_by_user_df, ratings = get_recommended_hotel_id(user_id) # hotels_went_by_user_df, ratings\n",
    "\n",
    "                hotels_went_by_user_df[\"UserId\"] = hotels_went_by_user_df[\"UserId\"].map(user_encoded2user)\n",
    "                hotels_went_by_user_df[\"HotelId\"] = hotels_went_by_user_df[\"HotelId\"].map(hotel_encoded2hotel)\n",
    "\n",
    "                recommended_hotel = pd.DataFrame(ratings)[0].map(hotel_encoded2hotel)\n",
    "\n",
    "                print(\"History:\")\n",
    "                display(hotels_went_by_user_df)\n",
    "                \n",
    "                print(\"Top 10 hotel recommendations:\")\n",
    "                print(\"----\" * 8)\n",
    "                for row in recommended_hotel:\n",
    "                    print(row)\n",
    "\n",
    "        else: print(\"Sorry, User has no recorded history!!!\")\n",
    "\n",
    "        # session.execute(\"INSERT INTO user_reviews (r_id, user_name, location_hotel, hotel_name, rating, comment) VALUES (%s, %s, %s, %s, %s, %s)\",\n",
    "                # (num_id + x, df_hotel.User_name, df_hotel.Location_hotel, df_hotel.Hotel_name, float(df_hotel.Rating), df_hotel.Comment))\n",
    "        sleep(4)\n",
    "        clear_output(wait=True) \n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"break\")\n",
    "        break\n",
    "print(\"Live view ended...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
